---
layout: post
title:  "定时任务框架Elastic-Job和Quartz"
categories: Quartz
tags: Quartz Elastic-Job
author: 百味皆苦
music-id: 5188665
---

* content
{:toc}
### 简介

#### Elastic-Job

- 支持集群，支持分布式（将一个任务拆分成多个独立的任务项，由分布式服务器分别执行某一个或几个分片项），不支持动态添加任务
- 分布式调度解决方案，使用jar包提供协调服务
- 外部依赖ZooKeeper（作为注册中心）进行集群
- 使用分片概念：一个任务拆分为多个独立的任务项，每个服务获得一个或几个分片项（用两个服务器遍历数据库的某张表，每个服务器执行任务的一般，A服务器获取id为奇数的数据，B服务器获取id为偶数的数据）
- 三种任务类型：Simple，Dataflow，Script
- 三种整合方式：javaAPI，spring，**springboot**
- 高级知识：自定义分片，作业监听器，事件追踪
- 实战应用：订单自动取消，第三方订单抓取

#### Quartz

- 支持集群，伪分布式，支持动态添加任务

- 基础知识：Job和JobDetail，Trigger触发器，**Cron表达式**
- 三种整合方式：javaAPI，spring，springboot
- 高级知识：Job监听器，Trigger监听器，Scheduler监听器，**Quartz集群**
- 实战应用：按小时统计订单信息

### Elastic-Job

#### Simple作业

- 意为定时任务的简单实现，只需要实现execute方法
- 提供了弹性扩容和分片功能
- 操作步骤：
  - 实现SimpleJob接口，实现execute方法
  - 定义作业核心配置（作业名称，定时策略，分片总数）
  - 定义作业类型（Simple，Dataflow，Script，实现类的全包名）
  - 定义Lite作业根配置（overwrite属性的重要性）
  - 配置注册中心ZooKeeper（可以单机，可以集群）。包括ip，端口，命名空间
  - 编写Main函数，启动定时任务
  - 新增启动配置，修改端口，启动定时任务第二个实例
  - 控制台观察两个实例打印出的分片项

```xml
<dependency>
      <groupId>com.dangdang</groupId>
      <artifactId>elastic-job-lite-core</artifactId>
      <version>2.1.5</version>
</dependency>
```

- job

```java
import com.dangdang.ddframe.job.api.ShardingContext;
import com.dangdang.ddframe.job.api.simple.SimpleJob;

import java.time.LocalTime;

public class MySimpleJob implements SimpleJob {
    @Override
    public void execute(ShardingContext shardingContext) {
        LocalTime time = LocalTime.now();
        System.out.println(time+",我是分片项："+shardingContext.getShardingItem()+
                ",总分片项："+shardingContext.getShardingTotalCount()+",taskId"+
                shardingContext.getTaskId());
    }
}
```

- 主函数

```java
/**
 * Hello world!
 *
 */
public class App {
    public static void main( String[] args )    {
        System.out.println( "Hello World!" );
        new JobScheduler(zkCenter(),configuration()).init();
    }

    /**
     * zookeeper注册中心
     * @return
     */
    public static CoordinatorRegistryCenter zkCenter(){
        ZookeeperConfiguration zc = new ZookeeperConfiguration("localhost:2181",
                "java-simple-job");

        ZookeeperRegistryCenter crc=new ZookeeperRegistryCenter(zc);
        //注册中心初始化
        crc.init();
        return crc;
    }


    /**
     * job配置
     * @return
     */
    public static LiteJobConfiguration configuration() {
        //job核心配置，每5秒执行一次任务，2个分片
        JobCoreConfiguration jcc = JobCoreConfiguration
                .newBuilder("mySimpleJob","0/5 * * * * ?",2)
                .build();
        //job类型配置，传入job类的全包名
        SimpleJobConfiguration jtc = new SimpleJobConfiguration(jcc,
                MySimpleJob.class.getCanonicalName());

        //job根的配置（LiteJobConfiguration）
        LiteJobConfiguration ljc = LiteJobConfiguration
                .newBuilder(jtc)
                .overwrite(true)
                .build();

        return ljc;
    }
 
}
```

- 先启动一次Main函数类，发现打印结果为：我是分片项0，总分片项2，我是分片项1，总分片项2
- 再启动一个Main函数类，发现第一个控制台输出：我是分片项0，总分片项2。第二个控制台输出：我是分片项1，总分片项2
- 验证了分片处理

#### Dataflow

- Dataflow类型用于处理流式作业，分为数据抓取（fetchData）和数据处理（processData）
- 应用场景：适用于不间断的数据处理，比如第三方订单的抓取
- 执行流程：
  - 定时任务根据规则触发
  - 抓取数据
  - 处理数据，完成后再次抓取
  - 若数据存在，继续处理；若不存在，则本次任务结束
  - 等待任务规则，下次触发
- 实现DataflowJob接口，注意`DataflowJob<T>`泛型，泛型规定了抓取数据的返回类型
- 案例：处理100个订单，分片处理，每次处理10个订单

```java
//模拟订单
public class Order {
    private Integer orderId;
    //0：未处理；1：已处理
    private Integer status;

    public Integer getOrderId() {
        return orderId;
    }

    public void setOrderId(Integer orderId) {
        this.orderId = orderId;
    }

    public Integer getStatus() {
        return status;
    }

    public void setStatus(Integer status) {
        this.status = status;
    }

    @Override
    public String toString() {
        return "Order{" +
                "orderId=" + orderId +
                ", status=" + status +
                '}';
    }
}
```

- 流式任务

```java
import com.dangdang.ddframe.job.api.ShardingContext;
import com.dangdang.ddframe.job.api.dataflow.DataflowJob;
import com.example.model.Order;

import java.time.LocalTime;
import java.util.ArrayList;
import java.util.List;

import static java.util.stream.Collectors.toList;

public class MyDataflowJob implements DataflowJob<Order> {

    private List<Order> orders = new ArrayList<>();
	//初始化100个订单
    {
        for (int i=0;i<100;i++){
            Order order = new Order();
            order.setOrderId(i+1);
            //未处理
            order.setStatus(0);
            orders.add(order);
        }
    }

	//抓取数据
    @Override
    public List<Order> fetchData(ShardingContext shardingContext) {
        //订单号 % 分片总数 == 当前分片项
        List<Order> orderList = orders.stream().filter(o -> o.getStatus() == 0)
                .filter(o -> o.getOrderId() % shardingContext.getShardingTotalCount() == shardingContext.getShardingItem())
                .collect(toList());

        List<Order> subList = null;
        if (orderList!=null && orderList.size()>0){
            //如果list不为空，每次抓取10条
            subList  = orderList.subList(0, 10);

        }

        try {
            //模拟数据处理
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        LocalTime time = LocalTime.now();

        System.out.println(time+",我是分片项："+shardingContext.getShardingItem()+",我抓取的数据是："+subList);

        return subList;
    }

    //数据处理
    @Override
    public void processData(ShardingContext shardingContext, List<Order> data) {
        //修改订单状态为已处理
        data.forEach(o->o.setStatus(1));
        try {
            Thread.sleep(5000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        LocalTime time = LocalTime.now();
        System.out.println(time+",我是分片项："+shardingContext.getShardingItem()+",我正在处理数据！");
    }
}
```

- 主函数类

```java
public class App {
    public static void main( String[] args )    {
        System.out.println( "Hello World!" );
        new JobScheduler(zkCenter(),configurationDataflow()).init();
    }
    
    /**
     * zookeeper注册中心
     * @return
     */
    public static CoordinatorRegistryCenter zkCenter(){
        ZookeeperConfiguration zc = new ZookeeperConfiguration("localhost:2181",
                "java-simple-job");

        ZookeeperRegistryCenter crc=new ZookeeperRegistryCenter(zc);
        //注册中心初始化
        crc.init();
        return crc;
    }
    
    public static LiteJobConfiguration configurationDataflow() {
        //job核心配置
        var jcc = JobCoreConfiguration
                .newBuilder("myDataflowJob","0/10 * * * * ?",2)
                .build();

        //job类型配置,重复执行
        var jtc = new DataflowJobConfiguration(jcc,
                MyDataflowJob.class.getCanonicalName(),true);

        //job根的配置（LiteJobConfiguration）
        var ljc = LiteJobConfiguration
                .newBuilder(jtc)
                .overwrite(true)
                .build();

        return ljc;
    }
}
```

#### script作业

- 脚本类型作业
- 支持shell，Python，Perl等
- 无需编码，配置任务时，添加可执行脚本的命令，作业信息作为最后一个参数自动追加

```java
public class App {
    public static void main( String[] args )    {
        System.out.println( "Hello World!" );
        new JobScheduler(zkCenter(),configurationScript()).init();
    }
    public static LiteJobConfiguration configurationScript() {
        //job核心配置
        var jcc = JobCoreConfiguration
                .newBuilder("myScriptJob","0/10 * * * * ?",2)
                .misfire(false)
                .build();

        //job类型配置
        var jtc = new ScriptJobConfiguration(jcc,"d:/test.cmd");

        //job根的配置（LiteJobConfiguration）
        var ljc = LiteJobConfiguration
                .newBuilder(jtc)
                .overwrite(true)
                .build();

        return ljc;
    }
}
```

#### spring整合作业

- 使用spring的schema整合作业

```xml
<properties>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <maven.compiler.source>8</maven.compiler.source>
    <maven.compiler.target>8</maven.compiler.target>
    <spring.version>5.1.5.RELEASE</spring.version>
    <elasticjob.version>2.1.5</elasticjob.version>
  </properties>

  <dependencies>
    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
      <version>4.11</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.springframework</groupId>
      <artifactId>spring-context</artifactId>
      <version>${spring.version}</version>
    </dependency>
    <dependency>
      <groupId>org.springframework</groupId>
      <artifactId>spring-web</artifactId>
      <version>${spring.version}</version>
    </dependency>
    <dependency>
      <groupId>com.dangdang</groupId>
      <artifactId>elastic-job-lite-core</artifactId>
      <version>${elasticjob.version}</version>
    </dependency>
    <dependency>
      <groupId>com.dangdang</groupId>
      <artifactId>elastic-job-lite-spring</artifactId>
      <version>${elasticjob.version}</version>
    </dependency>
    <dependency>
      <groupId>org.projectlombok</groupId>
      <artifactId>lombok</artifactId>
      <version>1.18.6</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.slf4j</groupId>
      <artifactId>slf4j-log4j12</artifactId>
      <version>1.7.26</version>
    </dependency>
    <dependency>
      <groupId>org.apache.commons</groupId>
      <artifactId>commons-dbcp2</artifactId>
      <version>2.6.0</version>
    </dependency>
    <dependency>
      <groupId>org.quartz-scheduler</groupId>
      <artifactId>quartz</artifactId>
      <version>2.3.1</version>
    </dependency>
  </dependencies>
```



- 在web.xml中配置listener，监听spring容器

```xml
<!DOCTYPE web-app PUBLIC
 "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN"
 "http://java.sun.com/dtd/web-app_2_3.dtd" >

<web-app>
  <display-name>spring-elasticjob</display-name>
  <context-param>
    <param-name>contextConfigLocation</param-name>
    <param-value>classpath*:spring-config.xml</param-value>
  </context-param>

  <listener>
    <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
  </listener>

</web-app>

```

- 编辑作业

```java
@Slf4j
public class MySimpleJob implements SimpleJob {
    @Override
    public void execute(ShardingContext shardingContext) {
        log.info("我是分片项："+shardingContext.getShardingItem());
    }
}
```

```java
public class MyDataflowJob implements DataflowJob<Integer> {

    private List<Integer> list = new ArrayList<>();

    {
        list.add(0);
        list.add(1);
        list.add(2);
        list.add(3);
        list.add(4);
        list.add(5);
        list.add(6);
        list.add(7);
        list.add(8);
        list.add(9);

    }

    @Override
    public List<Integer> fetchData(ShardingContext shardingContext) {
        //数字 % 分片总数 == 当前分片项
        List<Integer> rtnList = new ArrayList<>();
        for (Integer index : list){
            if (index % shardingContext.getShardingTotalCount() == shardingContext.getShardingItem()){
                rtnList.add(index);
                break;
            }
        }
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("我是分片项："+shardingContext.getShardingItem()+"，我获取的数据是："+rtnList);

        return rtnList;
    }

    @Override
    public void processData(ShardingContext shardingContext, List<Integer> data) {
        list.removeAll(data);
        try {
            Thread.sleep(5000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("我是分片项："+shardingContext.getShardingItem()+"，我移除数据是："+data);
    }
}
```



- 在xml中配置zookeeper注册中心，配置作业

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:reg="http://www.dangdang.com/schema/ddframe/reg"
       xmlns:job="http://www.dangdang.com/schema/ddframe/job"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
       http://www.springframework.org/schema/beans/spring-beans.xsd
            http://www.dangdang.com/schema/ddframe/reg
            http://www.dangdang.com/schema/ddframe/reg/reg.xsd
            http://www.dangdang.com/schema/ddframe/job
            http://www.dangdang.com/schema/ddframe/job/job.xsd
">
    <bean id="dataSource" class="org.apache.commons.dbcp2.BasicDataSource">
        <property name="username" value="root"/>
        <property name="password" value="123456"/>
        <property name="url" value="jdbc:mysql://localhost:3306/dataflow?serverTimezone=Asia/Shanghai&amp;useSSL=false"/>
    </bean>



    <!--注册中心配置-->
    <reg:zookeeper server-lists="localhost:2181" base-sleep-time-milliseconds="" namespace="spring-elasticjob" id="zkCenter"/>

    <!--simple作业配置-->
    <!--<job:simple id="mySimpleJob" registry-center-ref="zkCenter" cron="0/10 * * * * ?" sharding-total-count="2"-->
                <!--class="com.example.job.MySimpleJob" overwrite="true"/>-->

    <!--Dataflow作业-->
    <job:dataflow registry-center-ref="zkCenter" cron="0/10 * * * * ?" sharding-total-count="2" id="myDataflowJob"
                  class="com.example.job.MyDataflowJob" event-trace-rdb-data-source="dataSource"  overwrite="true" streaming-process="true" >
        <job:listener class=""/>
        <job:distributed-listener class="" started-timeout-milliseconds="" completed-timeout-milliseconds=""/>
        
    </job:dataflow>
</beans>
```



- 放入Tomcat启动定时任务



#### springboot整合作业

```xml
<dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.dangdang</groupId>
            <artifactId>elastic-job-lite-core</artifactId>
            <version>2.1.5</version>
        </dependency>
        <dependency>
            <groupId>com.dangdang</groupId>
            <artifactId>elastic-job-lite-spring</artifactId>
            <version>2.1.5</version>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-configuration-processor</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>8.0.15</version>
        </dependency>
        <dependency>
            <groupId>org.mybatis.spring.boot</groupId>
            <artifactId>mybatis-spring-boot-starter</artifactId>
            <version>2.0.0</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>org.mybatis.generator</groupId>
                <artifactId>mybatis-generator-maven-plugin</artifactId>
                <version>1.3.7</version>
                <dependencies>
                    <dependency>
                        <groupId>mysql</groupId>
                        <artifactId>mysql-connector-java</artifactId>
                        <version>8.0.15</version>
                    </dependency>
                </dependencies>
            </plugin>
        </plugins>
    </build>
```

- 目录结构
  - com.example
    - autoconfig
    - springbootelasticjob
  - resources
    - META-INF

- 编写zookeeper中心配置类

```java
package com.example.autoconfig;
@ConfigurationProperties(prefix = "elasticjob.zookeeper")
@Setter@Getter
public class ZookeeperProperties {
    //zookeeper地址列表
    private String serverList;
    //zookeeper命名空间
    private String namespace;

}
```

```properties
elasticjob.zookeeper.server-list=localhost:2181
elasticjob.zookeeper.namespace=springboot-elasticjob

spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.url=jdbc:mysql://localhost:3306/dataflow?serverTimezone=Asia/Shanghai&useSSL=false

mybatis.mapper-locations=/mybatis/*.xml
logging.pattern.dateformat=HH:mm:ss
```



- zookeeper中心自动配置

```java
package com.example.autoconfig;
@Configuration
@ConditionalOnProperty("elasticjob.zookeeper.server-list")
@EnableConfigurationProperties(ZookeeperProperties.class)
public class ZookeeperAutoConfig {

    @Autowired
    private ZookeeperProperties zookeeperProperties;

    /**
     * zookeeper注册中心
     * @return
     */
    @Bean(initMethod = "init")
    public CoordinatorRegistryCenter zkCenter(){
        String serverList = zookeeperProperties.getServerList();
        String namespace = zookeeperProperties.getNamespace();
        var zc = new ZookeeperConfiguration(serverList,namespace);

        var crc=new ZookeeperRegistryCenter(zc);

        return crc;
    }

}
```



- 导入自动配置处理依赖，属性文件自动提示

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-configuration-processor</artifactId>
    <optional>true</optional>
</dependency>
```



- 编写@ElasticSimpleJob注解

```java
package com.example.autoconfig;
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Component
public @interface ElasticSimpleJob {
    //作业名称
    String jobName() default "";
    //定时表达式
    String cron() default "";
    //总分片数
    int shardingTotalCount() default 1;
    //是否覆盖zookeeper中的配置
    boolean overwrite() default false;
    //作业优先级别
    Class<? extends JobShardingStrategy> jobStrategy() default AverageAllocationJobShardingStrategy.class;
    boolean jobEvent() default false;
    Class<? extends ElasticJobListener>[] jobListner() default {};
}
```

```java
package com.example.autoconfig;
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Component
public @interface ElasticDataflowJob {

    //作业名称
    String jobName() default "";
    //定时表达式
    String cron() default "";
    //总分片数
    int shardingTotalCount() default 1;
    //是否覆盖zookeeper中的配置
    boolean overwrite() default false;
    //是否开启流式处理
    boolean streamingProcess() default false;
    Class<? extends JobShardingStrategy> jobStrategy() default AverageAllocationJobShardingStrategy.class;
    boolean jobEvent() default false;
    Class<? extends ElasticJobListener>[] jobListner() default {};
}
```



- 使用java反射完成作业注册

```java
package com.example.autoconfig;
@Configuration
@ConditionalOnBean(CoordinatorRegistryCenter.class)
@AutoConfigureAfter(ZookeeperAutoConfig.class)
public class SimpleJobAutoConfig {

    @Autowired
    private CoordinatorRegistryCenter zkCenter;

    @Autowired
    private ApplicationContext applicationContext;

    @Autowired
    private DataSource dataSource;

    @PostConstruct
    public void initSimpleJob() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException {
        //获取所有标注了作业注解的bean
        Map<String, Object> beans = applicationContext.getBeansWithAnnotation(ElasticSimpleJob.class);
        for (Map.Entry<String, Object> entry : beans.entrySet()){
            Object instance = entry.getValue();
            Class<?>[] interfaces = instance.getClass().getInterfaces();
            for (Class<?> superInterface : interfaces){
                //如果作业类实现了SimpleJob这个接口就进行注册
                if (superInterface == SimpleJob.class){
                    //获取作业注解信息
                    ElasticSimpleJob annotation = instance.getClass().getAnnotation(ElasticSimpleJob.class);
                    String jobName = annotation.jobName();
                    String cron = annotation.cron();
                    int shardingTotalCount = annotation.shardingTotalCount();
                    boolean overwrite = annotation.overwrite();
                    Class<?> jobStrategy = annotation.jobStrategy();
                    boolean isJobEvent = annotation.jobEvent();
                    Class<? extends ElasticJobListener>[] listeners = annotation.jobListner();
                    ElasticJobListener[] listenerInstances = null;
                    //如果监听器不为空且长度大于0
                    if (listeners!=null && listeners.length>0){
                        listenerInstances = new ElasticJobListener[listeners.length];
                        int i = 0;
                        for (Class<? extends ElasticJobListener> listener : listeners){
                            ElasticJobListener listenerInstance = listener.getDeclaredConstructor().newInstance();
                            listenerInstances[i] = listenerInstance;
                            i++;
                        }
                    }else {
                        listenerInstances = new ElasticJobListener[0];
                    }


                    //job核心配置
                    var jcc = JobCoreConfiguration
                            .newBuilder(jobName,cron,shardingTotalCount)
                            .build();
                    //job类型配置
                    var jtc = new SimpleJobConfiguration(jcc,
                            instance.getClass().getCanonicalName());

                    //job根的配置（LiteJobConfiguration）
                    var ljc = LiteJobConfiguration
                            .newBuilder(jtc)
                            .jobShardingStrategyClass(jobStrategy.getCanonicalName())
                            .overwrite(overwrite)
                            .build();

                    if (isJobEvent){
                        JobEventConfiguration jec = new JobEventRdbConfiguration(dataSource);
                        new SpringJobScheduler((ElasticJob) instance,zkCenter,ljc,jec,listenerInstances).init();
                    }else {
                        new SpringJobScheduler((ElasticJob) instance,zkCenter,ljc,listenerInstances).init();
                    }
                }
            }
        }
    }

}
```

```java
@Configuration
@ConditionalOnBean(CoordinatorRegistryCenter.class)
@AutoConfigureAfter(ZookeeperAutoConfig.class)
public class DataflowJobAutoConfig {

    @Autowired
    private CoordinatorRegistryCenter zkCenter;

    @Autowired
    private ApplicationContext applicationContext;

    @Autowired
    private DataSource dataSource;

    @PostConstruct
    public void initDataflowJob() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException {
        Map<String, Object> beans = applicationContext.getBeansWithAnnotation(ElasticDataflowJob.class);
        for (Map.Entry<String, Object> entry : beans.entrySet()){
            Object instance = entry.getValue();
            Class<?>[] interfaces = instance.getClass().getInterfaces();
            for (Class<?> superInterface : interfaces){
                if (superInterface == DataflowJob.class){
                    ElasticDataflowJob annotation = instance.getClass().getAnnotation(ElasticDataflowJob.class);
                    String jobName = annotation.jobName();
                    String cron = annotation.cron();
                    int shardingTotalCount = annotation.shardingTotalCount();
                    boolean overwrite = annotation.overwrite();
                    boolean streamingProcess = annotation.streamingProcess();
                    Class<?> jobStrategy = annotation.jobStrategy();
                    boolean isJobEvent = annotation.jobEvent();
                    Class<? extends ElasticJobListener>[] listeners = annotation.jobListner();
                    ElasticJobListener[] listenerInstances = null;
                    if (listeners!=null && listeners.length>0){
                        listenerInstances = new ElasticJobListener[listeners.length];
                        int i = 0;
                        for (Class<? extends ElasticJobListener> listener : listeners){
                            ElasticJobListener listenerInstance = listener.getDeclaredConstructor().newInstance();
                            listenerInstances[i] = listenerInstance;
                            i++;
                        }
                    }else {
                        listenerInstances = new ElasticJobListener[0];
                    }
                    //job核心配置
                    var jcc = JobCoreConfiguration
                            .newBuilder(jobName,cron,shardingTotalCount)
                            .build();

                    //job类型配置
                    var jtc = new DataflowJobConfiguration(jcc,
                            instance.getClass().getCanonicalName(),streamingProcess);

                    //job根的配置（LiteJobConfiguration）
                    var ljc = LiteJobConfiguration
                            .newBuilder(jtc)
                            .jobShardingStrategyClass(jobStrategy.getCanonicalName())
                            .overwrite(overwrite)
                            .build();

                    if (isJobEvent){
                        JobEventConfiguration jec = new JobEventRdbConfiguration(dataSource);
                        new SpringJobScheduler((ElasticJob) instance,zkCenter,ljc,jec,listenerInstances).init();
                    }else {
                        new SpringJobScheduler((ElasticJob) instance,zkCenter,ljc,listenerInstances).init();
                    }
                }
            }
        }
    }
}
```



- 编写作业实现类，在类上加@ElasticSimpleJob注解

```java
package com.example.springbootelasticjob.job;
@Slf4j
@ElasticSimpleJob(
        jobName = "mySimpleJob" ,
        cron = "0/5 * * * * ?",
        shardingTotalCount = 1,
        overwrite = true
)
public class MySimpleJob implements SimpleJob {
    @Autowired
    private OrderService orderService;

    @Override
    public void execute(ShardingContext shardingContext) {

        for (int i=0;i<10;i++){
            orderService.insertOrder();
        }

    }
}
```

```java
package com.example.springbootelasticjob.job;
@Slf4j
@ElasticDataflowJob(
        jobName = "myDataflowJob",
        cron = "0/10 * * * * ?",
        shardingTotalCount = 2,
        overwrite = true,
        streamingProcess = true
)
public class MyDataflowJob implements DataflowJob<Integer> {

    private List<Integer> list = new ArrayList<>();

    {
        list.add(0);
        list.add(1);
        list.add(2);
        list.add(3);
        list.add(4);
        list.add(5);
        list.add(6);
        list.add(7);
        list.add(8);
        list.add(9);
    }

    @Override
    public List<Integer> fetchData(ShardingContext shardingContext) {
        List<Integer> rtnList = new ArrayList<>();
        //数字 % 分片总数 == 当前分片项
        for (Integer index : list){
            if (index % shardingContext.getShardingTotalCount() == shardingContext.getShardingItem()){
                rtnList.add(index);
                break;
            }
        }

        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        log.info("我是分片项："+shardingContext.getShardingItem()+"，我是抓取的数据是："+rtnList);

        return rtnList;
    }

    @Override
    public void processData(ShardingContext shardingContext, List<Integer> data) {
        list.removeAll(data);
        try {
            Thread.sleep(5000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        log.info("我是分片项："+shardingContext.getShardingItem()+"我移除了数据："+data);
    }
}
```



- 为了把项目打成jar包后能让其他项目也能使用到我们自定义的自动配置，需要在resources目录下创建META-INF文件夹，创建spring.factories文件

```
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
com.example.autoconfig.ZookeeperAutoConfig,\
com.example.autoconfig.SimpleJobAutoConfig,\
com.example.autoconfig.DataflowJobAutoConfig
```

- 启动项目进行测试

#### 定时轮询取消订单

- 模拟30分钟未支付订单自动取消
- 模拟订单生成过程
- 编写创建订单方法
- 配置定时任务每5秒执行一次
- 编写超时订单sql
- 使用多线程取消订单
- 使用乐观锁实现取消订单业务（根据update_time）
- Junit测试取消订单业务是否正确
- 使用@ElasticSimpleJob配置分片总数，定时规则
- 启动定时任务，测试功能正确性