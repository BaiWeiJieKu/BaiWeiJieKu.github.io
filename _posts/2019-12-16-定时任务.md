---
layout: post
title:  "定时任务框架Elastic-Job和Quartz"
categories: Quartz
tags: Quartz Elastic-Job
author: 百味皆苦
music-id: 5188665
---

* content
{:toc}
### 简介

#### Elastic-Job

- 支持集群，支持分布式（将一个任务拆分成多个独立的任务项，由分布式服务器分别执行某一个或几个分片项），不支持动态添加任务
- 分布式调度解决方案，使用jar包提供协调服务
- 外部依赖ZooKeeper（作为注册中心）进行集群
- 使用分片概念：一个任务拆分为多个独立的任务项，每个服务获得一个或几个分片项（用两个服务器遍历数据库的某张表，每个服务器执行任务的一般，A服务器获取id为奇数的数据，B服务器获取id为偶数的数据）
- 三种任务类型：Simple，Dataflow，Script
- 三种整合方式：javaAPI，spring，**springboot**
- 高级知识：自定义分片，作业监听器，事件追踪
- 实战应用：订单自动取消，第三方订单抓取

#### Quartz

- 支持集群，伪分布式，支持动态添加任务

- 基础知识：Job和JobDetail，Trigger触发器，**Cron表达式**
- 三种整合方式：javaAPI，spring，springboot
- 高级知识：Job监听器，Trigger监听器，Scheduler监听器，**Quartz集群**
- 实战应用：按小时统计订单信息

### Elastic-Job

#### Simple作业

- 意为定时任务的简单实现，只需要实现execute方法
- 提供了弹性扩容和分片功能
- 操作步骤：
  - 实现SimpleJob接口，实现execute方法
  - 定义作业核心配置（作业名称，定时策略，分片总数）
  - 定义作业类型（Simple，Dataflow，Script，实现类的全包名）
  - 定义Lite作业根配置（overwrite属性的重要性）
  - 配置注册中心ZooKeeper（可以单机，可以集群）。包括ip，端口，命名空间
  - 编写Main函数，启动定时任务
  - 新增启动配置，修改端口，启动定时任务第二个实例
  - 控制台观察两个实例打印出的分片项

```xml
<dependency>
      <groupId>com.dangdang</groupId>
      <artifactId>elastic-job-lite-core</artifactId>
      <version>2.1.5</version>
    </dependency>
```

- job

```java
import com.dangdang.ddframe.job.api.ShardingContext;
import com.dangdang.ddframe.job.api.simple.SimpleJob;

import java.time.LocalTime;

public class MySimpleJob implements SimpleJob {
    @Override
    public void execute(ShardingContext shardingContext) {
        LocalTime time = LocalTime.now();
        System.out.println(time+",我是分片项："+shardingContext.getShardingItem()+
                ",总分片项："+shardingContext.getShardingTotalCount()+",taskId"+
                shardingContext.getTaskId());
    }
}
```

- 主函数

```java
/**
 * Hello world!
 *
 */
public class App {
    public static void main( String[] args )    {
        System.out.println( "Hello World!" );
        new JobScheduler(zkCenter(),configuration()).init();
    }

    /**
     * zookeeper注册中心
     * @return
     */
    public static CoordinatorRegistryCenter zkCenter(){
        ZookeeperConfiguration zc = new ZookeeperConfiguration("localhost:2181",
                "java-simple-job");

        ZookeeperRegistryCenter crc=new ZookeeperRegistryCenter(zc);
        //注册中心初始化
        crc.init();
        return crc;
    }


    /**
     * job配置
     * @return
     */
    public static LiteJobConfiguration configuration() {
        //job核心配置，每5秒执行一次任务，2个分片
        JobCoreConfiguration jcc = JobCoreConfiguration
                .newBuilder("mySimpleJob","0/5 * * * * ?",2)
                .build();
        //job类型配置，传入job类的全包名
        SimpleJobConfiguration jtc = new SimpleJobConfiguration(jcc,
                MySimpleJob.class.getCanonicalName());

        //job根的配置（LiteJobConfiguration）
        LiteJobConfiguration ljc = LiteJobConfiguration
                .newBuilder(jtc)
                .overwrite(true)
                .build();

        return ljc;
    }
 
}
```

- 先启动一次Main函数类，发现打印结果为：我是分片项0，总分片项2，我是分片项1，总分片项2
- 再启动一个Main函数类，发现第一个控制台输出：我是分片项0，总分片项2。第二个控制台输出：我是分片项1，总分片项2
- 验证了分片处理

#### Dataflow

- Dataflow类型用于处理流式作业，分为数据抓取（fetchData）和数据处理（processData）
- 应用场景：适用于不间断的数据处理，比如第三方订单的抓取
- 执行流程：
  - 定时任务根据规则触发
  - 抓取数据
  - 处理数据，完成后再次抓取
  - 若数据存在，继续处理；若不存在，则本次任务结束
  - 等待任务规则，下次触发
- 实现DataflowJob接口，注意`DataflowJob<T>`泛型，泛型规定了抓取数据的返回类型
- 案例：处理100个订单，分片处理，每次处理10个订单

```java
//模拟订单
public class Order {
    private Integer orderId;
    //0：未处理；1：已处理
    private Integer status;

    public Integer getOrderId() {
        return orderId;
    }

    public void setOrderId(Integer orderId) {
        this.orderId = orderId;
    }

    public Integer getStatus() {
        return status;
    }

    public void setStatus(Integer status) {
        this.status = status;
    }

    @Override
    public String toString() {
        return "Order{" +
                "orderId=" + orderId +
                ", status=" + status +
                '}';
    }
}
```

- 流式任务

```java
import com.dangdang.ddframe.job.api.ShardingContext;
import com.dangdang.ddframe.job.api.dataflow.DataflowJob;
import com.example.model.Order;

import java.time.LocalTime;
import java.util.ArrayList;
import java.util.List;

import static java.util.stream.Collectors.toList;

public class MyDataflowJob implements DataflowJob<Order> {

    private List<Order> orders = new ArrayList<>();
	//初始化100个订单
    {
        for (int i=0;i<100;i++){
            Order order = new Order();
            order.setOrderId(i+1);
            //未处理
            order.setStatus(0);
            orders.add(order);
        }
    }

	//抓取数据
    @Override
    public List<Order> fetchData(ShardingContext shardingContext) {
        //订单号 % 分片总数 == 当前分片项
        List<Order> orderList = orders.stream().filter(o -> o.getStatus() == 0)
                .filter(o -> o.getOrderId() % shardingContext.getShardingTotalCount() == shardingContext.getShardingItem())
                .collect(toList());

        List<Order> subList = null;
        if (orderList!=null && orderList.size()>0){
            //如果list不为空，每次抓取10条
            subList  = orderList.subList(0, 10);

        }

        try {
            //模拟数据处理
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        LocalTime time = LocalTime.now();

        System.out.println(time+",我是分片项："+shardingContext.getShardingItem()+",我抓取的数据是："+subList);

        return subList;
    }

    //数据处理
    @Override
    public void processData(ShardingContext shardingContext, List<Order> data) {
        //修改订单状态为已处理
        data.forEach(o->o.setStatus(1));
        try {
            Thread.sleep(5000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        LocalTime time = LocalTime.now();
        System.out.println(time+",我是分片项："+shardingContext.getShardingItem()+",我正在处理数据！");
    }
}
```

- 主函数类

```java
public class App {
    public static void main( String[] args )    {
        System.out.println( "Hello World!" );
        new JobScheduler(zkCenter(),configurationDataflow()).init();
    }
    
    /**
     * zookeeper注册中心
     * @return
     */
    public static CoordinatorRegistryCenter zkCenter(){
        ZookeeperConfiguration zc = new ZookeeperConfiguration("localhost:2181",
                "java-simple-job");

        ZookeeperRegistryCenter crc=new ZookeeperRegistryCenter(zc);
        //注册中心初始化
        crc.init();
        return crc;
    }
    
    public static LiteJobConfiguration configurationDataflow() {
        //job核心配置
        var jcc = JobCoreConfiguration
                .newBuilder("myDataflowJob","0/10 * * * * ?",2)
                .build();

        //job类型配置,重复执行
        var jtc = new DataflowJobConfiguration(jcc,
                MyDataflowJob.class.getCanonicalName(),true);

        //job根的配置（LiteJobConfiguration）
        var ljc = LiteJobConfiguration
                .newBuilder(jtc)
                .overwrite(true)
                .build();

        return ljc;
    }
}
```

